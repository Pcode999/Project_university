import os
import cv2
import dlib
import numpy as np
import face_recognition
from imutils import face_utils
import time
import threading
from collections import deque

class OptimizedFaceSleepDetector:
    def __init__(self):
        self.known_face_encodings = []
        self.known_face_names = []
        self.detector = None
        self.predictor = None
        
        # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö multi-threading
        self.frame_queue = deque(maxlen=2)
        self.result_queue = deque(maxlen=2)
        self.processing = False
        
        # ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û
        self.face_detection_scale = 0.3  # ‡∏•‡∏î‡∏Ç‡∏ô‡∏≤‡∏î‡∏†‡∏≤‡∏û‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
        self.process_every_n_frames = 1  # ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏ó‡∏∏‡∏Å 2 ‡πÄ‡∏ü‡∏£‡∏°
        
    def load_known_faces(self, image_folder="images"):
        """‡πÇ‡∏´‡∏•‡∏î‡∏†‡∏≤‡∏û‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏à‡∏î‡∏à‡∏≥‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤"""
        print("üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏£‡∏π‡πâ‡∏à‡∏±‡∏Å...")
        
        if not os.path.exists(image_folder):
            print(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå {image_folder}")
            return False
        
        # ‡πÇ‡∏´‡∏•‡∏î‡∏†‡∏≤‡∏û‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÑ‡∏ü‡∏•‡πå
        loaded_count = 0
        for filename in os.listdir(image_folder):
            if filename.lower().endswith((".jpg", ".jpeg", ".png")):
                image_path = os.path.join(image_folder, filename)
                print(f"üì∑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î: {filename}")
                
                try:
                    # ‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏†‡∏≤‡∏û
                    image = face_recognition.load_image_file(image_path)
                    
                    # ‡∏•‡∏î‡∏Ç‡∏ô‡∏≤‡∏î‡∏†‡∏≤‡∏û‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß
                    height, width = image.shape[:2]
                    if width > 800:
                        scale = 800 / width
                        new_width = int(width * scale)
                        new_height = int(height * scale)
                        image = cv2.resize(image, (new_width, new_height))
                    
                    # ‡∏´‡∏≤‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û
                    face_locations = face_recognition.face_locations(image, model="hog")
                    
                    if face_locations:
                        # ‡πÉ‡∏ä‡πâ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÅ‡∏£‡∏Å‡∏ó‡∏µ‡πà‡∏û‡∏ö
                        face_encodings = face_recognition.face_encodings(image, face_locations)
                        if face_encodings:
                            self.known_face_encodings.append(face_encodings[0])
                            name = os.path.splitext(filename)[0]
                            self.known_face_names.append(name)
                            loaded_count += 1
                            print(f"‚úÖ ‡πÄ‡∏û‡∏¥‡πà‡∏° {name} ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
                    else:
                        print(f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏£‡∏π‡∏õ {filename}")
                        
                except Exception as e:
                    print(f"‚ùå ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏Å‡∏±‡∏ö {filename}: {e}")
        
        print(f"üìã ‡πÇ‡∏´‡∏•‡∏î‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {loaded_count} ‡∏Ñ‡∏ô")
        return loaded_count > 0
    
    def load_models(self, predictor_path="shape_predictor_68_face_landmarks.dat"):
        """‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• dlib"""
        print("üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•...")
        
        if not os.path.exists(predictor_path):
            print(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå {predictor_path}")
            print("üì• ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏î‡πâ‡∏à‡∏≤‡∏Å: http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2")
            return False
        
        try:
            self.detector = dlib.get_frontal_face_detector()
            self.predictor = dlib.shape_predictor(predictor_path)
            print("‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
            return True
        except Exception as e:
            print(f"‚ùå ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}")
            return False
    
    def calculate_ear(self, eye_points):
        """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Eye Aspect Ratio"""
        # ‡∏£‡∏∞‡∏¢‡∏∞‡∏´‡πà‡∏≤‡∏á‡πÅ‡∏ô‡∏ß‡∏ï‡∏±‡πâ‡∏á
        A = np.linalg.norm(eye_points[1] - eye_points[5])
        B = np.linalg.norm(eye_points[2] - eye_points[4])
        
        # ‡∏£‡∏∞‡∏¢‡∏∞‡∏´‡πà‡∏≤‡∏á‡πÅ‡∏ô‡∏ß‡∏ô‡∏≠‡∏ô
        C = np.linalg.norm(eye_points[0] - eye_points[3])
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì EAR
        ear = (A + B) / (2.0 * C)
        return ear
    
    def detect_drowsiness(self, landmarks):
        """‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏á‡πà‡∏ß‡∏á‡∏ô‡∏≠‡∏ô"""
        # ‡∏î‡∏∂‡∏á‡∏à‡∏∏‡∏î‡∏ï‡∏≤‡∏ã‡πâ‡∏≤‡∏¢‡πÅ‡∏•‡∏∞‡∏Ç‡∏ß‡∏≤
        left_eye = landmarks[36:42]
        right_eye = landmarks[42:48]
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì EAR ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ï‡∏≤
        left_ear = self.calculate_ear(left_eye)
        right_ear = self.calculate_ear(right_eye)
        
        # ‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢
        avg_ear = (left_ear + right_ear) / 2.0
        
        # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞
        if avg_ear > 0.25:
            return "ACTIVE", (0, 255, 0), left_eye, right_eye
        elif avg_ear > 0.20:
            return "DROWSY", (0, 165, 255), left_eye, right_eye
        else:
            return "SLEEPING", (0, 0, 255), left_eye, right_eye
    
    def process_frame_fast(self, frame):
        """‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÄ‡∏ü‡∏£‡∏°‡πÅ‡∏ö‡∏ö‡πÄ‡∏£‡πá‡∏ß"""
        try:
            # ‡∏•‡∏î‡∏Ç‡∏ô‡∏≤‡∏î‡∏†‡∏≤‡∏û‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö
            small_frame = cv2.resize(frame, None, fx=self.face_detection_scale, fy=self.face_detection_scale)
            rgb_small_frame = cv2.cvtColor(small_frame, cv2.COLOR_BGR2RGB)
            gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
            face_locations = face_recognition.face_locations(rgb_small_frame, model="hog")
            
            # ‡∏õ‡∏£‡∏±‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏Å‡∏•‡∏±‡∏ö‡∏°‡∏≤‡∏Ç‡∏ô‡∏≤‡∏î‡πÄ‡∏î‡∏¥‡∏°
            face_locations = [(int(top/self.face_detection_scale), int(right/self.face_detection_scale), 
                             int(bottom/self.face_detection_scale), int(left/self.face_detection_scale))
                             for (top, right, bottom, left) in face_locations]
            
            results = []
            
            if face_locations:
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏î‡πâ‡∏ß‡∏¢ dlib
                dlib_faces = self.detector(gray_frame)
                
                for (top, right, bottom, left) in face_locations:
                    name = "Unknown"
                    status = "ACTIVE"
                    color = (0, 255, 0)
                    eye_points = []
                    
                    # ‡∏à‡∏î‡∏à‡∏≥‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
                    if self.known_face_encodings:
                        try:
                            face_encodings = face_recognition.face_encodings(
                                cv2.cvtColor(frame, cv2.COLOR_BGR2RGB), 
                                [(top, right, bottom, left)]
                            )
                            
                            if face_encodings:
                                # ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏£‡∏π‡πâ‡∏à‡∏±‡∏Å
                                distances = face_recognition.face_distance(self.known_face_encodings, face_encodings[0])
                                if len(distances) > 0:
                                    best_match_index = np.argmin(distances)
                                    if distances[best_match_index] < 0.5:  # ‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏Å‡∏≤‡∏£‡∏à‡∏î‡∏à‡∏≥
                                        name = self.known_face_names[best_match_index]
                        except:
                            pass
                    
                    # ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏á‡πà‡∏ß‡∏á‡∏ô‡∏≠‡∏ô
                    for face in dlib_faces:
                        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤ dlib ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö face_recognition ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
                        if abs(face.left() - left) < 100 and abs(face.top() - top) < 100:
                            try:
                                landmarks = self.predictor(gray_frame, face)
                                landmarks = face_utils.shape_to_np(landmarks)
                                
                                status, color, left_eye, right_eye = self.detect_drowsiness(landmarks)
                                eye_points = [left_eye, right_eye]
                                
                            except Exception as e:
                                print(f"‚ö†Ô∏è ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏ï‡∏≤: {e}")
                            break
                    
                    results.append({
                        'box': (left, top, right, bottom),
                        'name': name,
                        'status': status,
                        'color': color,
                        'eye_points': eye_points
                    })
            
            return results
            
        except Exception as e:
            print(f"‚ùå ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•: {e}")
            return []
    
    def draw_results(self, frame, results):
        """‡∏ß‡∏≤‡∏î‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ö‡∏ô‡πÄ‡∏ü‡∏£‡∏°"""
        for result in results:
            left, top, right, bottom = result['box']
            name = result['name']
            status = result['status']
            color = result['color']
            eye_points = result['eye_points']
            
            # ‡∏ß‡∏≤‡∏î‡∏Å‡∏£‡∏≠‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
            cv2.rectangle(frame, (left, top), (right, bottom), color, 3)
            
            # ‡∏ß‡∏≤‡∏î‡∏à‡∏∏‡∏î‡∏ï‡∏≤
            for eye in eye_points:
                for (x, y) in eye:
                    cv2.circle(frame, (x, y), 2, (255, 255, 0), -1)
            
            # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
            text = f"{name} - {status}"
            
            # ‡∏ß‡∏≤‡∏î‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
            (text_width, text_height), baseline = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.8, 2)
            cv2.rectangle(frame, (left, top - text_height - 10), 
                         (left + text_width + 10, top), color, -1)
            
            # ‡∏ß‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
            cv2.putText(frame, text, (left + 5, top - 5), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)
        
        return frame
    
    def run(self):
        """‡∏£‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö"""
        print("üé• ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏Å‡∏•‡πâ‡∏≠‡∏á...")
        
        # ‡πÄ‡∏õ‡∏¥‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á
        cap = cv2.VideoCapture(0)
        if not cap.isOpened():
            print("‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏õ‡∏¥‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÑ‡∏î‡πâ")
            return False
        
        # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏Å‡∏•‡πâ‡∏≠‡∏á
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
        cap.set(cv2.CAP_PROP_FPS, 30)
        cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)  # ‡∏•‡∏î buffer ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î lag
        
        frame_count = 0
        fps_counter = 0
        fps_start_time = time.time()
        current_fps = 0
        last_results = []
        
        print("üöÄ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö (‡∏Å‡∏î 'q' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏¢‡∏∏‡∏î)")
        print("üìå Tips: ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÉ‡∏´‡πâ‡πÅ‡∏ô‡πà‡πÉ‡∏à‡∏ß‡πà‡∏≤‡∏°‡∏µ‡πÅ‡∏™‡∏á‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠‡πÅ‡∏•‡∏∞‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏°‡∏∏‡∏°‡∏°‡∏≠‡∏á‡∏Å‡∏•‡πâ‡∏≠‡∏á")
        
        try:
            while True:
                ret, frame = cap.read()
                if not ret:
                    print("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡πà‡∏≤‡∏ô‡πÄ‡∏ü‡∏£‡∏°‡πÑ‡∏î‡πâ")
                    continue
                
                frame_count += 1
                fps_counter += 1
                frame = cv2.flip(frame, 1)  # ‡∏û‡∏•‡∏¥‡∏Å‡πÅ‡∏ô‡∏ß‡∏ô‡∏≠‡∏ô
                
                # ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏ó‡∏∏‡∏Å N ‡πÄ‡∏ü‡∏£‡∏°
                if frame_count % self.process_every_n_frames == 0:
                    results = self.process_frame_fast(frame)
                    if results:  # ‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
                        last_results = results
                
                # ‡∏ß‡∏≤‡∏î‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
                if last_results:
                    frame = self.draw_results(frame, last_results)
                else:
                    # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
                    cv2.putText(frame, "No Face Detected", (50, 100), 
                               cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
                
                # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÅ‡∏•‡∏∞‡πÅ‡∏™‡∏î‡∏á FPS
                current_time = time.time()
                if current_time - fps_start_time >= 1.0:
                    current_fps = fps_counter
                    fps_counter = 0
                    fps_start_time = current_time
                
                cv2.putText(frame, f"FPS: {current_fps}", (10, 30), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)
                
                # ‡πÅ‡∏™‡∏î‡∏á‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏£‡∏π‡πâ‡∏à‡∏±‡∏Å
                if self.known_face_names:
                    cv2.putText(frame, f"Known: {len(self.known_face_names)} faces", (10, 60), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
                
                cv2.imshow("Face & Sleep Detection", frame)
                
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏Å‡∏î‡∏õ‡∏∏‡πà‡∏°
                key = cv2.waitKey(1) & 0xFF
                if key == ord('q') or key == 27:
                    break
                
        except KeyboardInterrupt:
            print("\nüõë ‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÇ‡∏î‡∏¢‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ")
        except Exception as e:
            print(f"‚ùå ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}")
        finally:
            cap.release()
            cv2.destroyAllWindows()
            print("üèÅ ‡∏õ‡∏¥‡∏î‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢")
        
        return True

def main():
    detector = OptimizedFaceSleepDetector()
    
    # ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•
    if not detector.load_models():
        print("‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏î‡πâ")
        print("üì• ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î shape_predictor_68_face_landmarks.dat")
        return
    
    # ‡πÇ‡∏´‡∏•‡∏î‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏£‡∏π‡πâ‡∏à‡∏±‡∏Å (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)
    if os.path.exists("images"):
        detector.load_known_faces()
    else:
        print("üìÅ ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå images - ‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÅ‡∏ö‡∏ö Unknown ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô")
        print("üí° ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå images ‡πÅ‡∏•‡∏∞‡πÉ‡∏™‡πà‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ‡∏Å‡∏≤‡∏£‡∏à‡∏î‡∏à‡∏≥‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤")
    
    # ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö
    detector.run()

if __name__ == "__main__":
    main()